{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b09e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b894e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"iris\", \"iris.data\"), header=None)\n",
    "\n",
    "classes = np.unique(df[4].values)\n",
    "df[4] = df[4].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afb5a7",
   "metadata": {},
   "source": [
    "### Divide the dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_iris_data(df, training_split=0.5, random_state=None):\n",
    "    setosa = df[df[4] == 0]\n",
    "    versicolor = df[df[4] == 1] \n",
    "    virginica = df[df[4] == 2]\n",
    "\n",
    "    # Randomly split each class into the training set\n",
    "    train_set = pd.concat([setosa.sample(frac=training_split, random_state=random_state),\n",
    "                            versicolor.sample(frac=training_split, random_state=random_state),\n",
    "                            virginica.sample(frac=training_split, random_state=random_state)])\n",
    "\n",
    "    # The remaining data composes the test set\n",
    "    test_set = df.drop(train_set.index)\n",
    "\n",
    "    # Shuffle both datasets\n",
    "    train_set = train_set.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    test_set = test_set.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Make training targets and features\n",
    "    train_features = train_set.drop(columns=[4]).values\n",
    "    train_targets = train_set[4].values\n",
    "    # Make test targets and features\n",
    "    test_features = test_set.drop(columns=[4]).values\n",
    "    test_targets = test_set[4].values\n",
    "\n",
    "    return train_features, train_targets, test_features, test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda65ae",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff1f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_labels = [self._predict(x) for x in X]\n",
    "        return np.array(predicted_labels)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.x_train]\n",
    "\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        majority = Counter(k_nearest_labels).most_common(1)\n",
    "        return majority[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "928838c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K = 3\n",
      "Mean Accuracy: 0.960667\n",
      "Mean Variance: 0.000417\n"
     ]
    }
   ],
   "source": [
    "run_acc = []\n",
    "k = 3\n",
    "for i in range(20):\n",
    "    # Split the data\n",
    "    x_train, y_train, x_test, y_test = split_iris_data(df, training_split=0.5)\n",
    "\n",
    "    # Fitting and predictions\n",
    "    knn = KNearestNeighbors(k = k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    predictions = knn.predict(x_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    y_test_array = y_test\n",
    "    acc = np.sum(predictions == y_test_array) / len(y_test_array)\n",
    "\n",
    "    run_acc.append(acc)\n",
    "  \n",
    "knn_acc = np.mean(run_acc)\n",
    "knn_var = np.var(run_acc)\n",
    "print(f'For K = {k}')\n",
    "print(f'Mean Accuracy: {knn_acc:.6f}')\n",
    "print(f'Mean Variance: {knn_var:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
